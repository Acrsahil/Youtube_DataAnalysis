from datetime import datetime
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


!pip install google-api-python-client
!pip install pandas
!pip install IPython



from googleapiclient.discovery import build 
import os
import pandas as pd
from IPython.display import JSON





# reading api_key from file
api_key = ""
with open("key.txt","r") as f:
    api_key = f.read()


    # Get credentials and create an API client

api_service_name = "youtube"
api_version = "v3"
youtube = build (
    api_service_name, api_version, developerKey=api_key )
channel_id = "UCX6OQ3DkcsbYNE6H8uQQuVA"


# -*- coding: utf-8 -*-

def get_channels(youtube,channel_id):
    total_data = []
    request = youtube.channels().list(
        part="snippet,contentDetails,statistics",
        id=channel_id
    )
    response = request.execute()
    

    # loop through items
    for item in response['items']:
        data = {
                "Channel_Name" : item['snippet']['title'],
                "Suscribers" : item['statistics']['subscriberCount'],
                "View" : item['statistics']['viewCount'],
                "TotalVideo" : item['statistics']['videoCount'],
                "PlaylistId" : item['contentDetails']['relatedPlaylists']['uploads']
               }

    total_data.append(data)
    return pd.DataFrame(total_data)

def get_videos(youtube, video_id):
    video_ids = []
    request = youtube.playlistItems().list(
        part="snippet,contentDetails",
        playlistId=video_id,
        maxResults = 50
    )
    response = request.execute()
    
    for item in response['items']:
        video_ids.append(item['contentDetails']['videoId'])
    next_page_token = response.get('nextPageToken')

    while next_page_token is not None:
        request = youtube.playlistItems().list(
            part="snippet,contentDetails",
            playlistId=video_id,
            maxResults = 50,
            pageToken=next_page_token
        )
        response = request.execute()
        for item in response['items']:
            video_ids.append(item['contentDetails']['videoId'])
        next_page_token = response.get('nextPageToken')
        # print(len(video_ids))
        
    return video_ids

channel_data = get_channels(youtube, channel_id)
video_id = str(channel_data['PlaylistId'][0]).strip()
video_ids =  get_videos(youtube, video_id)






def get_video_data(video_ids):
    # Get video data for the given video IDs in chunks of 50
    all_video_data = []
    
    for i in range(0, len(video_ids), 50):
        batch_ids = video_ids[i:i + 50]
        
        # Request video details in chunks
        video_response = youtube.videos().list(
            part="snippet,contentDetails,statistics",
            id=",".join(batch_ids)
        ).execute()
        
        # Extend the result into all_video_data
        all_video_data.extend(video_response.get("items", []))
    
    return all_video_data



response = get_video_data(video_ids)
JSON(response)




#create a dictionary which will store columns of our data
my_video_data = {
    'video_id' : [],
    'channel_title' : [],
    'title' : [],
    'description' : [],
    'published_at' : [],
    'view_count' : [],
    'like_Count' : [],
    'favourite_Count' : [],
    'duration' : [],
    'caption' : [],
    'defination' : [],
    'commentCount' : []
}






for item in response:
    my_video_data['video_id'].append(item.get('id', '0'))
    my_video_data['channel_title'].append(item['snippet'].get('channelTitle', '0'))
    my_video_data['title'].append(item['snippet'].get('title', '0'))
    my_video_data['description'].append(item['snippet'].get('description', '0'))
    my_video_data['like_Count'].append(item['statistics'].get('likeCount', '0'))
    my_video_data['favourite_Count'].append(item['statistics'].get('favoriteCount', '0'))
    my_video_data['duration'].append(item['contentDetails'].get('duration', '0'))
    my_video_data['caption'].append(item['contentDetails'].get('caption', '0'))
    my_video_data['defination'].append(item['contentDetails'].get('definition', '0'))
    my_video_data['view_count'].append(item['statistics'].get('viewCount', '0'))
    my_video_data['published_at'].append(item['snippet'].get('publishedAt', '0'))
    my_video_data['commentCount'].append(item['statistics'].get('commentCount', '0'))



for key, value in my_video_data.items():
    print(f"{key}: {len(value)}")





df = pd.DataFrame(my_video_data)
df


#checking for null values
df.isnull().any()


df.dtypes


df['like_Count'] = df['like_Count'].apply(pd.to_numeric)
df['favourite_Count'] = df['favourite_Count'].apply(pd.to_numeric)
df['commentCount'] = df['commentCount'].apply(pd.to_numeric)
df['view_count'] = df['view_count'].apply(pd.to_numeric)


# create link
df['video_link'] = df['video_id'].apply(lambda x: f"https://www.youtube.com/watch?v={x}")


#most viewed video
df[df['view_count'] == df['view_count'].max()].video_link


df[df['view_count'] == df['view_count'].min()].video_link



df['view_count'].describe


df.columns


df['Published_date'] = df['published_at'].str.split('T').str[0]


df['Published_time'] = df['published_at'].str.split('T').str[1]


len(df[df['Published_time'].str[-1] == 'Z'])


df['Published_time'] = df['Published_time'].str.replace('Z','')
df['Published_time']


import isodate


 df['duration'] = df['duration'].apply(
    lambda x: isodate.parse_duration(x) if isinstance(x, str) else None
)


df['duration']


from datetime import datetime, timedelta

df['duration'] = df['duration'].apply(lambda x: (datetime.min + x).time())


from  datetime import time
df['duration']


df['Published_date'] = pd.to_datetime(df['Published_date'])



df.columns





monthly_time_series = df.groupby(df['Published_date'].dt.month)['view_count'].sum().reset_index()
monthly_time_series.head()


plt.figure(figsize=(15, 6))
plt.title("Monthly view count")
sns.stripplot(data=monthly_time_series,x='Published_date',y='view_count')


daily_view = df.groupby(df['Published_date'].dt.day)['view_count'].sum().reset_index()


import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15,6))
sns.lineplot(data=daily_view, x='Published_date', y='view_count', marker='o')

# Ensure all unique days are shown
plt.xticks(
    ticks=daily_view['Published_date'],
    labels=daily_view['Published_date'],
    rotation=90
)

plt.xlabel("Day of Month")
plt.ylabel("View Count")
plt.title("Daily View Count for the Month")
plt.grid(True)
plt.tight_layout()
plt.show()



df.columns


df.set_index('Published_date', inplace=True)
df.reset_index(inplace=True)
df['month_name'] = df['Published_date'].dt.month_name()

# Step 3: Count uploads per month
monthly_uploads = df['month_name'].value_counts().reindex([
    'January', 'February', 'March', 'April', 'May', 'June',
    'July', 'August', 'September', 'October', 'November', 'December'
])

# Step 4: Plot
plt.figure(figsize=(10, 5))
monthly_uploads.plot(kind='bar', color='skyblue')
plt.title('Total Video Uploads by Month')
plt.xlabel('Month')
plt.ylabel('Number of Uploads')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

df.reset_index(inplace=True)



df.set_index('Published_date', inplace=True)
yearly_uploads = df.resample('Y').size()
yearly_uploads.index = yearly_uploads.index.year

plt.figure(figsize=(12, 6))
plt.plot(yearly_uploads.index, yearly_uploads, label='Yearly Uploads', color='blue', marker='o')
plt.title('Video Uploads Over Time (Yearly)')
plt.xlabel('Year')
plt.ylabel('Number of Videos Uploaded')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.show()
